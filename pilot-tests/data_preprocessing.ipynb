{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be4c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 59 images...\n",
      "Created 94 training images\n",
      "Created 23 testing images\n",
      "Created 94 training images\n",
      "Created 23 testing images\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "from PIL import Image\n",
    "import typing as t\n",
    "import cv2 as cv\n",
    "from cv2.typing import MatLike\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Configuration\n",
    "ANALYZE_WIDTH = 220\n",
    "ANALYZE_HEIGHT = 88\n",
    "TRAIN_IMAGE_SIZE = (64, 32)\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "PATH_TRAINING_DATA = Path(\"./data/training\")\n",
    "PATH_TESTING_DATA = Path(\"./data/testing\")\n",
    "\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create clean training and testing directories.\"\"\"\n",
    "    for path in [PATH_TRAINING_DATA, PATH_TESTING_DATA]:\n",
    "        if path.exists() and path.is_dir():\n",
    "            shutil.rmtree(path)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def find_playhead_position(img: MatLike, template: MatLike) -> t.Tuple[int, int]:\n",
    "    \"\"\"Find the position of the playhead in the image using template matching.\"\"\"\n",
    "    res = cv.matchTemplate(img, template, cv.TM_CCOEFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    return (max_loc[0], max_loc[1])\n",
    "\n",
    "\n",
    "def extract_regions(img: MatLike, playhead_pos: t.Tuple[int, int], template_shape: t.Tuple[int, int]) -> t.Tuple[MatLike, MatLike]:\n",
    "    \"\"\"Extract left and right analysis regions around the playhead.\"\"\"\n",
    "    analyze_bbox_left = (playhead_pos[0] - ANALYZE_WIDTH, playhead_pos[1], \n",
    "                        playhead_pos[0], playhead_pos[1] + ANALYZE_HEIGHT)\n",
    "    analyze_bbox_right = (playhead_pos[0] + template_shape[1], playhead_pos[1], \n",
    "                         playhead_pos[0] + template_shape[1] + ANALYZE_WIDTH, playhead_pos[1] + ANALYZE_HEIGHT)\n",
    "    \n",
    "    img_left = img[analyze_bbox_left[1]:analyze_bbox_left[3], analyze_bbox_left[0]:analyze_bbox_left[2], :]\n",
    "    img_right = img[analyze_bbox_right[1]:analyze_bbox_right[3], analyze_bbox_right[0]:analyze_bbox_right[2], :]\n",
    "    \n",
    "    return img_left, img_right\n",
    "\n",
    "\n",
    "def save_training_images(img_bass: MatLike, img_breakdown: MatLike, is_training: bool):\n",
    "    \"\"\"Save bass and breakdown images to appropriate directories.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "    file_name_bass = f\"bass_{timestamp}.png\"\n",
    "    file_name_breakdown = f\"breakdown_{timestamp}.png\"\n",
    "    \n",
    "    # Convert BGR to RGB and resize\n",
    "    img_pil_bass = Image.fromarray(cv.cvtColor(img_bass, cv.COLOR_BGR2RGB)).resize(TRAIN_IMAGE_SIZE)\n",
    "    img_pil_breakdown = Image.fromarray(cv.cvtColor(img_breakdown, cv.COLOR_BGR2RGB)).resize(TRAIN_IMAGE_SIZE)\n",
    "    \n",
    "    # Save to appropriate directory\n",
    "    save_dir = PATH_TRAINING_DATA if is_training else PATH_TESTING_DATA\n",
    "    img_pil_bass.save(save_dir / file_name_bass)\n",
    "    img_pil_breakdown.save(save_dir / file_name_breakdown)\n",
    "\n",
    "\n",
    "def process_images():\n",
    "    \"\"\"Main function to process all images and create training/testing datasets.\"\"\"\n",
    "    # Load template and input images\n",
    "    playhead_template = cv.imread(\"./templates/playhead.png\")\n",
    "    images_bass = glob.glob(\"./data/raw/bass/*.png\")\n",
    "    images_breakdown = glob.glob(\"./data/raw/breakdown/*.png\")\n",
    "    all_images = images_bass + images_breakdown\n",
    "    \n",
    "    setup_directories()\n",
    "    \n",
    "    n_images = len(all_images)\n",
    "    print(f\"Processing {n_images} images...\")\n",
    "    \n",
    "    for i, img_path in enumerate(all_images):\n",
    "        img = cv.imread(img_path)\n",
    "        playhead_pos = find_playhead_position(img, playhead_template)\n",
    "        img_left, img_right = extract_regions(img, playhead_pos, playhead_template.shape)\n",
    "        \n",
    "        # Determine which region corresponds to which class\n",
    "        is_breakdown_source = \"breakdown\" in img_path\n",
    "        train_image_breakdown = img_right if is_breakdown_source else img_left\n",
    "        train_image_bass = img_left if is_breakdown_source else img_right\n",
    "        \n",
    "        # Determine if this goes to training or testing set\n",
    "        is_training = i < n_images * TRAIN_TEST_SPLIT\n",
    "        \n",
    "        save_training_images(train_image_bass, train_image_breakdown, is_training)\n",
    "    \n",
    "    print(f\"Created {int(n_images * TRAIN_TEST_SPLIT * 2)} training images\")\n",
    "    print(f\"Created {int(n_images * (1 - TRAIN_TEST_SPLIT) * 2)} testing images\")\n",
    "\n",
    "\n",
    "# Run the processing\n",
    "process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5174a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bass_breakdown_classifier.pkl\n",
      "Accuracy: 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bass       1.00      1.00      1.00        11\n",
      "   breakdown       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herrm\\Projects\\herrm\\ml-lightsequence\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib\n",
    "\n",
    "\n",
    "def load_dataset(folder: Path) -> tuple[np.ndarray, np.ndarray]:\n",
    "    images: list[np.ndarray] = []\n",
    "    labels: list[int] = []\n",
    "    for img_path in sorted(folder.glob(\"*.png\")):\n",
    "        label = 1 if \"breakdown\" in img_path.stem else 0\n",
    "        with Image.open(img_path) as img:\n",
    "            arr = np.asarray(img.convert(\"RGB\"), dtype=np.float32).reshape(-1)\n",
    "        images.append(arr)\n",
    "        labels.append(label)\n",
    "    if not images:\n",
    "        raise ValueError(f\"No PNG images found in {folder}\")\n",
    "    features = np.stack(images) / 255.0\n",
    "    targets = np.asarray(labels, dtype=np.int64)\n",
    "    return features, targets\n",
    "\n",
    "\n",
    "train_dir = Path(\"./data/training\")\n",
    "test_dir = Path(\"./data/testing\")\n",
    "\n",
    "x_train, y_train = load_dataset(train_dir)\n",
    "x_test, y_test = load_dataset(test_dir)\n",
    "\n",
    "model = make_pipeline(StandardScaler(with_mean=False), LinearSVC())\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = Path(\"./bass_breakdown_classifier.pkl\")\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"bass\", \"breakdown\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a86211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 96 images in 0.012 s\n",
      "Average latency per image: 0.123 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if \"model\" not in globals() or \"x_train\" not in globals():\n",
    "    raise RuntimeError(\"Run the training cell before benchmarking inference.\")\n",
    "\n",
    "# Measure single-image inference latency on the training set\n",
    "start = time.perf_counter()\n",
    "for sample in x_train:\n",
    "    _ = model.predict(sample.reshape(1, -1))\n",
    "total = time.perf_counter() - start\n",
    "per_image_ms = (total / x_train.shape[0]) * 1000.0\n",
    "\n",
    "print(f\"Predicted {x_train.shape[0]} images in {total:.3f} s\")\n",
    "print(f\"Average latency per image: {per_image_ms:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be053ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./bass_breakdown_classifier.pkl\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:1164: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'cv::matchTemplate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m img = cv.imread(\u001b[33m\"\u001b[39m\u001b[33mdata/raw/bass/bass_20251022_142938_107288.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m template = cv.imread(\u001b[33m\"\u001b[39m\u001b[33mtemplates/playhead_template.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m playhead_pos = \u001b[43mfind_playhead_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# from cell 1\u001b[39;00m\n\u001b[32m     88\u001b[39m result = predict_bass_or_breakdown(img, playhead_pos)\n\u001b[32m     89\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mfind_playhead_position\u001b[39m\u001b[34m(img, template)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_playhead_position\u001b[39m(img: MatLike, template: MatLike) -> t.Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the position of the playhead in the image using template matching.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     res = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatchTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTM_CCOEFF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (max_loc[\u001b[32m0\u001b[39m], max_loc[\u001b[32m1\u001b[39m])\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:1164: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'cv::matchTemplate'\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "from cv2.typing import MatLike\n",
    "import typing as t\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Configuration (must match training parameters)\n",
    "ANALYZE_WIDTH = 220\n",
    "ANALYZE_HEIGHT = 88\n",
    "TRAIN_IMAGE_SIZE = (64, 32)\n",
    "\n",
    "# Global model variable for efficiency\n",
    "_model = None\n",
    "\n",
    "\n",
    "def load_classifier_model(model_path: str = \"./bass_breakdown_classifier.pkl\"):\n",
    "    \"\"\"Load the trained classifier model. Call this once before inference.\"\"\"\n",
    "    global _model\n",
    "    if not Path(model_path).exists():\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    _model = joblib.load(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "\n",
    "def predict_bass_or_breakdown(img: MatLike, playhead_pos: t.Tuple[int, int], \n",
    "                             template_shape: t.Tuple[int, int] = (19, 88)) -> str:\n",
    "    \"\"\"\n",
    "    Predict whether the current state is 'bass' or 'breakdown' from a live image.\n",
    "    \n",
    "    Args:\n",
    "        img: Full captured image (BGR format from cv2)\n",
    "        playhead_pos: (x, y) position of the playhead\n",
    "        template_shape: (width, height) of the playhead template for region calculation\n",
    "    \n",
    "    Returns:\n",
    "        \"bass\" or \"breakdown\"\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    if _model is None:\n",
    "        raise RuntimeError(\"Model not loaded. Call load_classifier_model() first.\")\n",
    "    \n",
    "    # Extract analysis regions around the playhead\n",
    "    analyze_bbox_left = (playhead_pos[0] - ANALYZE_WIDTH, playhead_pos[1], \n",
    "                        playhead_pos[0], playhead_pos[1] + ANALYZE_HEIGHT)\n",
    "    analyze_bbox_right = (playhead_pos[0] + template_shape[1], playhead_pos[1], \n",
    "                         playhead_pos[0] + template_shape[1] + ANALYZE_WIDTH, playhead_pos[1] + ANALYZE_HEIGHT)\n",
    "    \n",
    "    img_left = img[analyze_bbox_left[1]:analyze_bbox_left[3], analyze_bbox_left[0]:analyze_bbox_left[2], :]\n",
    "    img_right = img[analyze_bbox_right[1]:analyze_bbox_right[3], analyze_bbox_right[0]:analyze_bbox_right[2], :]\n",
    "    \n",
    "    # Convert regions to RGB, resize, and flatten for model input\n",
    "    img_left_rgb = cv.cvtColor(img_left, cv.COLOR_BGR2RGB)\n",
    "    img_right_rgb = cv.cvtColor(img_right, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    img_left_pil = Image.fromarray(img_left_rgb).resize(TRAIN_IMAGE_SIZE)\n",
    "    img_right_pil = Image.fromarray(img_right_rgb).resize(TRAIN_IMAGE_SIZE)\n",
    "    \n",
    "    # Convert to feature vectors (same format as training)\n",
    "    left_features = np.asarray(img_left_pil, dtype=np.float32).reshape(-1) / 255.0\n",
    "    right_features = np.asarray(img_right_pil, dtype=np.float32).reshape(-1) / 255.0\n",
    "    \n",
    "    # Predict both regions\n",
    "    left_pred = _model.predict(left_features.reshape(1, -1))[0]\n",
    "    right_pred = _model.predict(right_features.reshape(1, -1))[0]\n",
    "    \n",
    "    # Logic: if left is breakdown, then current state is breakdown\n",
    "    # if right is breakdown, then current state is bass\n",
    "    if left_pred == 1:  # left is breakdown\n",
    "        return \"breakdown\"\n",
    "    elif right_pred == 1:  # right is breakdown\n",
    "        return \"bass\"\n",
    "    else:\n",
    "        # Both predict bass - need to determine which side we're looking at\n",
    "        # Default to bass if unclear\n",
    "        return \"bass\"\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "load_classifier_model()  # Call once at startup\n",
    "\n",
    "# During live inference:\n",
    "img = cv.imread(\"data/raw/bass/bass_20251022_142938_107288.png\")\n",
    "template = cv.imread(\"templates/playhead_template.png\")\n",
    "playhead_pos = find_playhead_position(img, template)  # from cell 1\n",
    "result = predict_bass_or_breakdown(img, playhead_pos)\n",
    "print(f\"Current state: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-lightsequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
